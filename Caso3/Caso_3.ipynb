{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1f826429-1b0b-452b-98d5-d724d06f8ba3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Explorando tendencias de mercado de Airbnb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "30017573-ddfa-442e-931f-69e52cab3f33",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "La ciudad de Nueva York tiene una variedad de anuncios de Airbnb para satisfacer la alta demanda de alojamiento temporal para viajeros, con diferentes niveles de precios, tipos de habitaciones y ubicaciones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9113a8f5-7192-4887-b383-2d285a405f0f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "La ciudad de Nueva York, es una de las ciudades más visitadas del mundo. Hay muchos anuncios de Airbnb en la ciudad de Nueva York para satisfacer la alta demanda de alojamiento temporal para viajeros, que puede durar desde unas pocas noches hasta muchos meses. En este proyecto, analizaremos más de cerca el mercado de Airbnb de Nueva York combinando datos de varios tipos de archivos como .csv, .tsv y .xlsx.\n",
    "\n",
    "Recuerde que los archivos CSV, TSV y Excel son tres formatos comunes para almacenar datos. Tiene a su disposición [tres archivos](https://tajamar365.sharepoint.com/:f:/s/3405-MasterIA2024-2025/EoXMgjAJLLNJqWDyKDig8kABSUkpWj_HGQjl267qNnHS9g?e=foxjFc) que contienen datos sobre los anuncios de Airbnb de 2019:  \n",
    "\n",
    "- `airbnb_price.csv `: Este es un archivo CSV que contiene datos sobre precios y ubicaciones de anuncios de Airbnb.  \n",
    "  1. `listing_id`: identificador único del anuncio  \n",
    "  2. `price`: precio del anuncio por noche en USD  \n",
    "  3. `nbhood_full`: nombre del distrito y del barrio donde se encuentra el anuncio  \n",
    "    \n",
    "\n",
    "- `airbnb_room_type.xlsx`: Este es un archivo Excel que contiene datos sobre las descripciones de los anuncios de Airbnb y los tipos de habitaciones.  \n",
    "  1. `listing_id`: identificador único del anuncio  \n",
    "  2. `description`: descripción del anuncio     \n",
    "  3. `room_type`: Airbnb tiene tres tipos de habitaciones: habitaciones compartidas, habitaciones privadas y casas o apartamentos completos \n",
    "\n",
    "\n",
    "- `airbnb_last_review.tsv`: Este es un archivo TSV que contiene datos sobre los nombres de los anfitriones de Airbnb y las fechas de revisión.  \n",
    "  1. `listing_id`: identificador único del anuncio  \n",
    "  2. `host_name`:  nombre del anfitrión del anuncio  \n",
    "  3. `last_review`: echa en la que se revisó el anuncio por última vez   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "bab5e15d-251d-4092-9ec3-61f8a0d84f43",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Como consultor que trabaja para una empresa inmobiliaria emergente, ha recopilado datos de anuncios de Airbnb de varias fuentes para investigar el mercado de alquileres a corto plazo en Nueva York. Analizará estos datos para brindar información sobre habitaciones privadas a la empresa inmobiliaria."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3db66806-50c8-46b2-ab8b-fb66b3602f7d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "- ¿Cuáles son las fechas de las primeras y las últimas reseñas? Almacene estos valores como dos variables independientes con los nombres que prefiera.\n",
    "- ¿Cuántos de los anuncios son habitaciones privadas? Guárdelo en cualquier variable.\n",
    "- ¿Cuál es el precio promedio de los anuncios? Redondee a los dos decimales más cercanos y guárdelo en una variable.\n",
    "- Combine las nuevas variables en un DataFrame llamado review_dates con cuatro columnas en el siguiente orden: first_reviewed, last_reviewed, nb_private_rooms y avg_price. El DataFrame solo debe contener una fila de valores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ce371640-56b7-4b1c-b2fc-2cac372d2942",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Preparativos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bc87f8df-a1fb-47d1-a2a4-54b38ad97511",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, min, max, count, avg, round, to_date\n",
    "\n",
    "spark = SparkSession.builder.appName(\"AirbnbDataProcessing\").getOrCreate()\n",
    "\n",
    "dfp=spark.read.load(path=\"dbfs:/FileStore/shared_uploads/sergio.ferreras@tajamar365.com/airbnb_price.csv\", format=\"csv\", header=\"true\", sep=\",\", inferSchema=\"true\")\n",
    "\n",
    "dft=spark.read.load(path=\"dbfs:/FileStore/shared_uploads/sergio.ferreras@tajamar365.com/airbnb_room_type.csv\", format=\"csv\", header=\"true\", sep=\";\", inferSchema=\"true\")\n",
    "\n",
    "dfr = spark.read.load(path=\"dbfs:/FileStore/shared_uploads/sergio.ferreras@tajamar365.com/airbnb_last_review.tsv\", format=\"csv\", header=\"true\", sep=\"\\t\", inferSchema=\"true\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "dd6a0002-2cca-4892-8d3f-a3b6ff55d465",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "¿Cuáles son las fechas de las primeras y las últimas reseñas? Almacene estos valores como dos variables independientes con los nombres que prefiera."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6e23cd25-11a8-4fd3-aa2f-192b13401232",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reseña más antigua:\nJanuary 01 2019\nReseña más reciente:\nJuly 09 2019\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import functions as F\n",
    "\n",
    "\n",
    "dfr = dfr.withColumn(\"last_review_date\", F.to_date(F.col(\"last_review\"), \"MMMM dd yyyy\"))\n",
    "\n",
    "reseñaantigua = dfr.orderBy(\"last_review_date\", ascending=True).first()\n",
    "reseñaantigua = reseñaantigua[\"last_review\"]\n",
    "\n",
    "reseñanueva = dfr.orderBy(\"last_review_date\", ascending=False).first()\n",
    "reseñanueva = reseñanueva[\"last_review\"]\n",
    "\n",
    "print(\"Reseña más antigua:\")\n",
    "print(reseñaantigua)\n",
    "print(\"Reseña más reciente:\")\n",
    "print(reseñanueva)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8bf47120-54a9-46a8-a4b4-b7a6a29d2b32",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "¿Cuántos de los anuncios son habitaciones privadas? Guárdelo en cualquier variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "84fd25f9-4139-495a-9d06-731ff27b8b2b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Habitaciones Privadas:\n7185\n"
     ]
    }
   ],
   "source": [
    "#filtramos las filas cogiendo las que tengan como tipo de habitacion Private Room\n",
    "npr = dft.filter(dft.room_type == \"Private room\").count()\n",
    "\n",
    "print(\"Habitaciones Privadas:\")\n",
    "print(npr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0af8b697-df99-44aa-902e-65e7f9d56f6c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "¿Cuál es el precio promedio de los anuncios? Redondee a los dos decimales más cercanos y guárdelo en una variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a93d0d5b-5d8b-4a2a-b203-3699695eb0ed",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "141.78\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import regexp_replace\n",
    "\n",
    "#primero hacemos una limpieza de los datos para eliminar todo lo que  no sean numeros\n",
    "dfp = dfp.withColumn(\n",
    "    \"price\", \n",
    "    regexp_replace(\"price\", \"[a-zA-Z\\\\s]\", \"\")\n",
    ")\n",
    "\n",
    "#usando avg hacemos una media del precio de todas las filas de price aproximandolo a 2 decimales y lo guardamos en una variable\n",
    "avg_price = dfp.select(round(avg(\"price\"), 2).alias(\"avg_price\")).collect()[0][\"avg_price\"]\n",
    "print(avg_price)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "88f363ad-647e-4bbc-bf6d-6b198da48ce9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Combine las nuevas variables en un DataFrame llamado review_dates con cuatro columnas en el siguiente orden: first_reviewed, last_reviewed, nb_private_rooms y avg_price. El DataFrame solo debe contener una fila de valores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4e177c85-67bc-4a2b-887b-6f5a7887184d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>first_reviewed</th><th>last_reviewed</th><th>nb_private_rooms</th><th>avg_price</th></tr></thead><tbody><tr><td>January 01 2019</td><td>July 09 2019</td><td>7185</td><td>141.78</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "January 01 2019",
         "July 09 2019",
         7185,
         141.78
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "first_reviewed",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "last_reviewed",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "nb_private_rooms",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "avg_price",
         "type": "\"double\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pyspark.sql import Row\n",
    "\n",
    "#creamos una fila en un nuevo dataframe usando Row donde ponemos los datos de las variable anteriores  \n",
    "review_data = Row(\n",
    "    first_reviewed=reseñaantigua,  \n",
    "    last_reviewed=reseñanueva,   \n",
    "    nb_private_rooms=npr,         \n",
    "    avg_price=avg_price           \n",
    ")\n",
    "\n",
    "review_dates = spark.createDataFrame([review_data])\n",
    "\n",
    "review_dates.display()"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Caso_3",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
